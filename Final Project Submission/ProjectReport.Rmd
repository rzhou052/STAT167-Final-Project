---
title: "Thisisafunnygroupname's Project Report"
author: "Richard Zhou, Adam Rui, Jonathan Darius, Ojasvi Godha, Ryan Huang, Isaac Kang"
output: 
  pdf_document:
    toc: true
---

\newpage

**[DELETE ALL TEXT IN BRACKETS AND TEMPLATE COMMENTS IN CODE WHEN FINISHED]**

# Introduction

[Write a quick introduction]

# Project Description

[Write about the project, our project objectives, and the questions we seek to answer]

Through this data analysis, we aim to answer the 5 following questions:

1.  Have flight delays improved over time overall?Â 

    -   What about with individual airlines?\

2.  Do busy destinations tend to have more or less delays?\

3.  Is the weather correlated with flight delays?

    -   How has this changed over time?\

4.  Is the time of the year correlated between flight delays (holidays or rainy season)?\

5.  Which airlines have the least delays?

    -   How has this changed over time?

\newpage

# Research Questions

## Objective 1 
#### Setting up packages and dataset 
```{r}
#install.packages("tidyverse")
#install.packages("nycflights13")
#install.packages("nycflights23")
#install.packages("dplyr")
#install.packages("gridExtra")
```
```{r}
library("tidyverse")
library("nycflights13")
library("nycflights23")
library("dplyr")
library("gridExtra")
library("ggplot2")
library("broom")
library(car)
library(sandwich)
library(lmtest)
```

```{r}
# cleaning dataset
flights_combined <- bind_rows(nycflights13::flights %>% mutate(year = 2013), nycflights23::flights %>% mutate(year = 2023))

flights_clean <- flights_combined %>%
  filter(!is.na(dep_delay), !is.na(arr_delay), dep_delay >= 0, arr_delay >= 0) %>%
  left_join(nycflights13::airlines, by = "carrier") %>%
  left_join(nycflights13::airports, by = c("dest" = "faa"))

colnames(flights_clean)
head(flights_clean)
```
### Part A: Have flight delays improved or gotten worse between 2013 and 2023?

```{r}
delay_by_carrier <- flights_clean %>%
  group_by(name.x, year) %>% #specifies to calculate the average fo each airline as well
  summarise(avg_dep_delay = mean(dep_delay), .groups = 'drop')

dep_delay_model <- lm(data=flights_clean, dep_delay~factor(year))
```

**First we test for normality. **
```{r}
qqnorm(residuals(dep_delay_model))
qqline(residuals(dep_delay_model), col = "red")
```
**We don't seem to meet this assumption so let's do a log transformation to help. And check the normality assumption again.**

```{r}
flights_clean$log_dep_delay <- log1p(flights_clean$dep_delay)
dep_delay_model_log <- lm(log_dep_delay ~ factor(year), data = flights_clean)

qqnorm(residuals(dep_delay_model_log))
qqline(residuals(dep_delay_model_log), col = "red")
```
**And since the points are close to the red line, we can claim that yes the data is from a normal population. **

```{r}
leveneTest(log_dep_delay ~ factor(year), data = flights_clean)
```
**We can also check for homoscedasticity using the Levene's Test which is not met. The small p-value here shows signs of heteroscedasticity which means we cannot use regular 'summary()' to get results of the model. Let's look into the model itself using robust standard errors which assumes unequal error variances.**

```{r}
coeftest(dep_delay_model_log, vcov = vcovHC)
```

**This model helps us see the overall difference in departure delays between 2013 and 2023. The model shows a statistically significant increase in departure delays from 2013 to 2023, indicated by a positive coefficient with a very small p-value. In this context, we can conclude that that flight departure delays have gotten worse over time.**




**Let's do the whole process again, with arrival delays.**
```{r}
arr_delay_model <- lm(data=flights_clean, arr_delay~factor(year))

qqnorm(residuals(arr_delay_model))
qqline(residuals(arr_delay_model), col = "red")
```
**We seem to have the same issue as the departure delays, so let's do another log transformation and test again.**

```{r}
flights_clean$log_arr_delay <- log1p(flights_clean$arr_delay)
arr_delay_model_log <- lm(log_arr_delay ~ factor(year), data = flights_clean)

qqnorm(residuals(arr_delay_model_log))
qqline(residuals(arr_delay_model_log), col = "red")
```

```{r}
leveneTest(log_arr_delay ~ factor(year), data = flights_clean)
```
**We can, again, check for homoscedasticity using the Levene's Test which is, again, not met. The small p-value here shows signs of heteroscedasticity which means we cannot use regular 'summary()' to get results of the model. Let's look into the model itself using robust standard errors which assumes unequal error variances.**

```{r}
coeftest(arr_delay_model_log, vcov = vcovHC)
```
**When we compare the arrival delays, we have a statistically significant increase as well, with a positive coefficient and small p-value, indicating that arrival delays have also gotten worse between 2013 and 2023, however slightly.**


**Let's take a quick look at the performance of both these arrival and delay models.**
```{r, collapse=TRUE}
print(paste('Arrival Adj R^2: ', summary(arr_delay_model_log)$adj.r.squared))

print(paste("Departure Adj R^2: ", summary(dep_delay_model_log)$adj.r.squared))
```
**The Adjusted R^2 value helps us measure the quality of the model. These are really small values which means these models are not great. But in this case the small values are fine as the dataset is large, and the focus of this question was to identify average differences in delays over time, so the models still provided meaningful insights for this question.**


**For some additional comparison, we can try to see how much more or less departure delays have changed versus arrival delays from 2013 to 2023.**

```{r}
both_delay_flights <- flights_clean %>%
  select(year, log_dep_delay, log_arr_delay) %>%
  pivot_longer(cols = c(log_dep_delay, log_arr_delay), 
               names_to = "delay_type", 
               values_to = "delay_value")

both_delay_model <- lm(data=both_delay_flights, delay_value~factor(year)*delay_type)
```

**Let's first check for the normality assumption.**
```{r}
qqnorm(residuals(both_delay_model))
qqline(residuals(both_delay_model))
```
**Based on this plot, we can say we meet the normality assumption. Now let's check for homoscedasticity with the Levene's Test.**

```{r}
leveneTest(delay_value ~ factor(year)*delay_type,  data = both_delay_flights)
```
**We can check for homoscedasticity using the Levene's Test which is, again, not met. The small p-value here shows signs of heteroscedasticity which means we cannot use regular 'summary()' to get results of the model. Let's look into the model itself using robust standard errors which assumes unequal error variances.**

```{r}
coeftest(both_delay_model, vcov = vcovHC)
```

**The key term in the model is 'factor(year)2023:delay_typedep_delay', which represents the additional change in departure delays from 2013 to 2023 relative to arrival delays. From the two previous models, we know arrival delays increased over the years by about 10% and departure delays increased by about 28%. In this combined model, we can see that as the coefficient is positive and, based on the p-value, is statistically significant. With this, we can conclude that the departure delays not only increased over time, but did so to a significantly greater extent than arrival delays did.**

### Part B: To expand on Part B, have individual airlines gotten better or worse with delays over time?
```{r}
delay_model_airline <- lm(data=flights_clean, log_dep_delay~factor(year) * name.x)
summary(delay_model_airline)
```
**Based on the F-statistic, this model is significant. However, there are a few airlines that seem to be discontinued in 2023, so lets remove them and create a new model.**

```{r}
# getting airlines that only appear in both years 
active_airlines <- flights_clean %>%
  group_by(name.x, year) %>%
  summarise(n = n(), .groups = "drop") %>%
  count(name.x) %>%
  filter(n == 2) %>%
  pull(name.x)

flights_filtered <- flights_clean %>%
  filter(name.x %in% active_airlines)


dep_delay_model_airline_filtered <- lm(data=flights_filtered, log_dep_delay~factor(year) * name.x)
```

**Now with our new model, let's check for the normality assumption.**
```{r}
qqnorm(residuals(dep_delay_model_airline_filtered))
qqline(residuals(dep_delay_model_airline_filtered))
```
**Based on this plot, we can say we meet the normality assumption. Now let's check for homoscedasticity with the Levene's Test.**

```{r}
leveneTest(log_dep_delay ~ factor(year) * name.x, data = flights_filtered)
```
**Based on the small p-value, we can see signs of heteroscedasticity which means we cannot use regular 'summary()' to get results of the model. Let's look into the model itself using robust standard errors which assumes unequal error variances.**

```{r}
dep_delay_robust_se <- vcovHC(dep_delay_model_airline_filtered, type = "HC1")
dep_delay_tidy_robust_model <- tidy(coeftest(dep_delay_model_airline_filtered, vcov. = dep_delay_robust_se))

# only getting interaction terms, what we need 
dep_interaction_terms <- dep_delay_tidy_robust_model[grep(":", dep_delay_tidy_robust_model$term),]
print(dep_interaction_terms)
```
**Based on the p-values, only 3 of these 10 airlines are statistically significant. Yet despite that we can still gain an idea of a general trend by looking at the coefficients. 6 out of 10 of these coefficients are positive, which means the majority of the airlines have gotten worse in 2023 compared to 2013.**

**Let's do this again with arrival delays.**
```{r}
arr_delay_model_airline_filtered <- lm(data=flights_filtered, log_arr_delay~factor(year) * name.x)
```

**Let's check for the normality assumption.**
```{r}
qqnorm(residuals(arr_delay_model_airline_filtered))
qqline(residuals(arr_delay_model_airline_filtered))
```
**Based on this plot, we can say we meet the normality assumption. Now let's check for homoscedasticity with the Levene's Test.**

```{r}
leveneTest(log_arr_delay ~ factor(year) * name.x, data = flights_filtered)
```
**Based on the small p-value, we can see signs of heteroscedasticity which means we cannot use regular 'summary()' to get results of the model. Let's look into the model itself using robust standard errors which assumes unequal error variances.**

```{r}
arr_delay_robust_se <- vcovHC(arr_delay_model_airline_filtered, type = "HC1")
arr_delay_tidy_robust_model <- tidy(coeftest(arr_delay_model_airline_filtered, vcov. = arr_delay_robust_se))

# only getting interaction terms, what we need 
arr_interaction_terms <- arr_delay_tidy_robust_model[grep(":", arr_delay_tidy_robust_model$term),]
print(arr_interaction_terms)
```
**Based on the p-values here, again only 3 of these 10 airlines are statistically significant. We can still gain an idea of a general trend by looking at the coefficients. 6 out of 10 of these coefficients are negative, opposite of the departure trends. This means the majority of the airlines have actually gotten better in 2023 compared to 2013.**

### Graphs 
```{r}
both_delay_filtered <- flights_filtered %>%
  select(year, name.x, dep_delay, arr_delay) %>%
  pivot_longer(cols = c(dep_delay, arr_delay),
               names_to = "delay_type",
               values_to = "delay_value")
```

**Here, we can easily how the average arrival and departure delays have changed between 2013 and 2023. It seems that both arrival and departure delays have gotten worse.**

```{r}
both_delay_filtered %>%
  group_by(name.x, year, delay_type) %>%
  summarise(mean_delay = mean(delay_value, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = mean_delay, color = name.x, group = name.x)) +
  geom_line(size = 1) +
  geom_point() +
  facet_wrap(~delay_type, scales = "free_y") +
  labs(title = "Trends in Delay by Airline (2013 vs 2023)",
       x = "Year", y = "Average Delay (min)") +
  theme_minimal() +
  theme(legend.position = "none") 
```


### Data Exploration and Visualization

```{r}
# reuse/refine the plot made in the proposal
```

[Discuss the visualization. What are some important takeaways? What could we possibly find interesting insights in judging from the plot? Any possible reasons for these insights? Talk about how your visualization leads to your analysis]

### Data Analysis/Modeling/Predictions

```{r}
# code for testing your hypotheses/models

# DON'T FORGET TO CHECK NECESSARY ASSUMPTIONS FOR PERFORMING ANALYSES
# there are plenty of premade functions to test assumptions, just search them up
```

[Discuss your results. Don't forget that no results is still an important conclusion, with plenty to discuss! What are some important takeaways? Any possible explanations for these takeaways? How can we apply this new found knowledge?]

## [Do busy destinations tend to have more or less delays?]

### Data Exploration and Visualization

```{r}
library("tidyverse")
library("nycflights13")
library("nycflights23")
library("dplyr")

flights_combined <- bind_rows(nycflights13::flights %>% mutate(year = 2013), nycflights23::flights %>% mutate(year = 2023))

flights_clean <- flights_combined %>%
  filter(!is.na(dep_delay), !is.na(arr_delay)) %>%
  left_join(nycflights13::airlines, by = "carrier") %>%
  left_join(nycflights13::airports, by = c("dest" = "faa"))

destination_stats <- flights_clean |>
  filter(!is.na(name.y)) |>
  group_by(dest, name.y) |>
  summarise(
    total_flights = n(),
    avg_delay = mean(dep_delay + arr_delay),
    .groups = "drop"
  ) |>
  mutate(
    busyness = total_flights / sum(total_flights),
    busyness_rank = dense_rank(busyness)
  ) %>%
  arrange(busyness_rank)

#_____________________ my stuff starts here the above is the data cleaning stuff_______________________
library("ggrepel") #for the floating text labels

important_airports <- destination_stats |>
  arrange(desc(avg_delay)) |>
  slice(c(1:5, (n()-4):n())) |>
  bind_rows(
    destination_stats |>
      arrange(desc(busyness)) |> 
      slice(1:5)  # 5 busiest
  ) |>
  distinct(dest, .keep_all = TRUE)

#for the correlation and p value
cor_test <- cor.test(destination_stats$busyness, destination_stats$avg_delay)
correlation <- cor_test$estimate
p_value <- cor_test$p.value

ggplot(destination_stats, aes(x = busyness, y = avg_delay)) +
  geom_point(aes(size = total_flights, color = avg_delay), alpha = 0.5) +
  
  #linear fit line
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  
  #floating text for impotant airports
  geom_text_repel(
    data = important_airports,
    aes(label = paste(dest, name.y)), 
    size = 3,
    box.padding = 0.5
  ) +
  
  #add colors to visualise delay better
  scale_color_gradient2(
    low = "green", mid = "blue", high = "red", 
    midpoint = median(destination_stats$avg_delay)
  ) +
  labs(
    x = "Proportion of Total Flights (Busyness)",
    y = "Average Delay (minutes)",
    title = "Flight Delays vs. Destination Busyness",
    subtitle = sprintf(
      "Correlation: %.2f (p = %.3f)", 
      correlation, 
      p_value
    ),
    size = "Total Flights",
    color = "Avg Delay"
  )
```

[Discuss the visualization. What are some important takeaways? What could we possibly find interesting insights in judging from the plot? Any possible reasons for these insights? Talk about how your visualization leads to your analysis]

### Data Analysis/Modeling/Predictions

```{r}
library(lmtest)
model <- lm(avg_delay ~ busyness, data = destination_stats)
bptest(model)  # p > 0.05 = homoscedastic

shapiro.test(residuals(model))

#accounting for heteroscedasticity (obust standard error)
library(sandwich)


#accounting for normality (np regression)
library(mgcv)
model_gam <- gam(avg_delay ~ s(busyness), data = destination_stats)
summary(model_gam)
```

[Discuss your results. Don't forget that no results is still an important conclusion, with plenty to discuss! What are some important takeaways? Any possible explanations for these takeaways? How can we apply this new found knowledge?]

## [REPLACE WITH QUESTION #3]

### Data Exploration and Visualization

```{r}
# reuse/refine the plot made in the proposal
```

[Discuss the visualization. What are some important takeaways? What could we possibly find interesting insights in judging from the plot? Any possible reasons for these insights? Talk about how your visualization leads to your analysis]

### Data Analysis/Modeling/Predictions

```{r}
# code for testing your hypotheses/models  

# DON'T FORGET TO CHECK NECESSARY ASSUMPTIONS FOR PERFORMING ANALYSES # there are plenty of premade functions to test assumptions, just search them up
```

[Discuss your results. Don't forget that no results is still an important conclusion, with plenty to discuss! What are some important takeaways? Any possible explanations for these takeaways? How can we apply this new found knowledge?]

## [REPLACE WITH QUESTION #4]

### Data Exploration and Visualization

```{r}
# reuse/refine the plot made in the proposal
```

[Discuss the visualization. What are some important takeaways? What could we possibly find interesting insights in judging from the plot? Any possible reasons for these insights? Talk about how your visualization leads to your analysis]

### Data Analysis/Modeling/Predictions

```{r}
# code for testing your hypotheses/models  

# DON'T FORGET TO CHECK NECESSARY ASSUMPTIONS FOR PERFORMING ANALYSES # there are plenty of premade functions to test assumptions, just search them up
```

[Discuss your results. Don't forget that no results is still an important conclusion, with plenty to discuss! What are some important takeaways? Any possible explanations for these takeaways? How can we apply this new found knowledge?]

## [REPLACE WITH QUESTION #5]

### Data Exploration and Visualization

```{r}
# reuse/refine the plot made in the proposal
```

[Discuss the visualization. What are some important takeaways? What could we possibly find interesting insights in judging from the plot? Any possible reasons for these insights? Talk about how your visualization leads to your analysis]

### Data Analysis/Modeling/Predictions

```{r}
# code for testing your hypotheses/models  

# DON'T FORGET TO CHECK NECESSARY ASSUMPTIONS FOR PERFORMING ANALYSES # there are plenty of premade functions to test assumptions, just search them up
```

[Discuss your results. Don't forget that no results is still an important conclusion, with plenty to discuss! What are some important takeaways? Any possible explanations for these takeaways? How can we apply this new found knowledge?]

\newpage

# Conclusions

1.  **Have flight delays improved over time overall?**

    -   **What about with individual airlines?**

[Write a quick paragraph recapping conclusions made from your analysis]

2.  **Do busy destinations tend to have more or less delays?**

[Write a quick paragraph recapping conclusions made from your analysis] i will do this tmrw i;m so sleepy

3.  **Is the weather correlated with flight delays?**

    -   **How has this changed over time?**

[Write a quick paragraph recapping conclusions made from your analysis]

4.  **Is the time of the year correlated between flight delays (holidays or rainy season)?**

[Write a quick paragraph recapping conclusions made from your analysis]

5.  **Which airlines have the least delays?**

    -   How has this changed over time?

[Write a quick paragraph recapping conclusions made from your analysis]

\newpage

# Authors' Contributions

| Author           | Contributions |
|------------------|---------------|
| Richard Zhou     |               |
| Adam Rui         |               |
| Jonathan Darius  |               |
| Ojasvi Godha     |               |
| Ryan Huang       | Question 2    |
| Isaac Kang       |               |
